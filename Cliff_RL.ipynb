{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cliff RL",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgFLfEpz1CyCnMXrySzijz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/burhanusman/RL-cliff-walking/blob/master/Cliff_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bluc7glbl4GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from copy import copy\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs2ww14oWcdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CliffRoad():\n",
        "    def __init__(self,nrow,ncol):\n",
        "      self.ncol=ncol\n",
        "      self.nrow=nrow\n",
        "      #0 - road, 1=Edge, 2=Cliff , 4 =Start 5=Win\n",
        "      self.road=np.zeros((self.nrow,self.ncol),np.int8)\n",
        "      self.road[0,:]=1\n",
        "      self.road[-1,1:-1]=2\n",
        "      self.road[-1,0]=4\n",
        "      self.road[-1,-1]=5\n",
        "      self.current_state=[nrow-1,0]\n",
        "      self.agent_path=[[0,0]]\n",
        "      self.reward_array=np.zeros((self.nrow,self.ncol))\n",
        "      self.full_action_list=[0,1,2,3]\n",
        "\n",
        "      #reward setting 1\n",
        "      self.reward_array[self.road!=2]=-1\n",
        "      self.reward_array[self.road==2]=-100\n",
        "\n",
        "      #reward setting 2\n",
        "      # self.reward_array[self.road==1]=-1\n",
        "      # self.reward_array[self.road==2]=-100\n",
        "      # self.reward_array[self.road==5]=100\n",
        "\n",
        "    def displayRoad(self):\n",
        "      print(self.road)\n",
        "    \n",
        "    #actions - 0:Up, 1=Right, 2=Down, 3=Left\n",
        "    def get_possible_actions(self,state):\n",
        "      row=state[0]\n",
        "      col=state[1]\n",
        "      full_action_list=self.full_action_list.copy()\n",
        "      last_row=self.nrow-1\n",
        "      last_col=self.ncol-1\n",
        "      if col==0:\n",
        "        full_action_list.remove(3)\n",
        "      if row==0:\n",
        "        full_action_list.remove(0)\n",
        "      if col==last_col:\n",
        "        full_action_list.remove(1)\n",
        "      if row==last_row:\n",
        "        full_action_list.remove(2)\n",
        "      return full_action_list\n",
        "    \n",
        "    def move_up(self,state):\n",
        "      return [state[0]-1,state[1]]\n",
        "    def move_down(self,state):\n",
        "      return [state[0]+1,state[1]]\n",
        "    def move_left(self,state):\n",
        "      return [state[0],state[1]-1]\n",
        "    def move_right(self,state):\n",
        "      return [state[0],state[1]+1]\n",
        "    \n",
        "    def is_done(self,state):\n",
        "      last_row=self.nrow-1\n",
        "      last_col=self.ncol-1\n",
        "      if state[0]==last_row and (state[1] != 0):\n",
        "        return True\n",
        "      return False\n",
        "\n",
        "    def step(self,action):\n",
        "      done=False\n",
        "      obs=self.current_state\n",
        "      if action==0:\n",
        "        next_state=self.move_up(obs)\n",
        "      if action==1:\n",
        "        next_state=self.move_right(obs)\n",
        "      if action==2:\n",
        "        next_state=self.move_down(obs)\n",
        "      if action==3:\n",
        "        next_state=self.move_left(obs)\n",
        "      reward=self.reward_array[next_state[0],next_state[1]]\n",
        "      done=self.is_done(next_state)\n",
        "      self.current_state=next_state\n",
        "      return next_state,reward,done\n",
        "\n",
        "    def show_agent_position(self):\n",
        "      agent_on_road=self.road.copy()\n",
        "      pos=self.current_state\n",
        "      agent_on_road[pos[0],pos[1]]=8\n",
        "      print(agent_on_road)\n",
        "\n",
        "    def reset(self):\n",
        "      self.current_state=[self.nrow-1,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDS65nqhhycV",
        "colab_type": "text"
      },
      "source": [
        "### Defining the agent and the requred q-table\n",
        "Number of states = row*col\n",
        "\n",
        "Ideally the Q table should contain number of states on rows, and actions on the columsn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RReNh46Bogih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent():\n",
        "  def __init__(self,road):\n",
        "    self.road=road\n",
        "    nrow=road.nrow\n",
        "    ncol=road.ncol\n",
        "    state_number=nrow*ncol\n",
        "    action_number=len(road.full_action_list)\n",
        "    self.q=np.full((state_number,action_number),0.5)\n",
        "    self.policy=np.zeros_like(road.road)\n",
        "\n",
        "  def state_encode(self,state):\n",
        "    ncol=self.road.ncol\n",
        "    encoded_state=state[0]*ncol+state[1]\n",
        "    return encoded_state\n",
        "  \n",
        "  def update_current_policy(self):\n",
        "    for i in range(self.policy.shape[0]):\n",
        "      for j in range(self.policy.shape[1]):\n",
        "        state=[i,j]\n",
        "        action_set=self.road.get_possible_actions(state)\n",
        "        q_state=self.state_encode(state)\n",
        "        self.policy[i,j]=action_set[np.argmax(self.q[q_state,action_set])]\n",
        "\n",
        "  def q_learn(self,episodes=100,alpha=.5,gamma=.99,epsilon=0.1):\n",
        "    for i in range(episodes):\n",
        "      self.road.reset()\n",
        "      done=False\n",
        "      while not done:\n",
        "        state=self.state_encode(self.road.current_state)\n",
        "        action_set=self.road.get_possible_actions(road.current_state)\n",
        "        explore_p=random.random()\n",
        "\n",
        "        #eps-policy for selecting next action\n",
        "        if explore_p<epsilon:\n",
        "          action=random.choice(action_set)\n",
        "        else:\n",
        "          action=action_set[np.argmax(self.q[state,action_set])]\n",
        "        \n",
        "        #Taking the above action, moving to the next state, and getting the corresponding reward.\n",
        "        next_state,reward,done=road.step(action)\n",
        "        q_next_state=self.state_encode(next_state)\n",
        "\n",
        "        #greedy-policy for selecting the next q-value\n",
        "        next_action_set=self.road.get_possible_actions(next_state)\n",
        "        #Greedy update \n",
        "        self.q[state,action]=self.q[state,action]+alpha*(reward+gamma*np.max(self.q[q_next_state,next_action_set])-self.q[state,action])\n",
        "    self.update_current_policy()\n",
        "\n",
        "  def sarsa(self,episodes=100,alpha=.5,gamma=.99,epsilon=0.1):\n",
        "    for i in range(episodes):\n",
        "      self.road.reset()\n",
        "      done=False\n",
        "      while not done:\n",
        "        state=self.state_encode(self.road.current_state)\n",
        "        action_set=self.road.get_possible_actions(road.current_state)\n",
        "        explore_p=random.random()\n",
        "\n",
        "        #eps-policy for selecting next action\n",
        "        if explore_p<epsilon:\n",
        "          action=random.choice(action_set)\n",
        "        else:\n",
        "          action=action_set[np.argmax(self.q[state,action_set])]\n",
        "        \n",
        "        #Taking the above action, moving to the next state, and getting the corresponding reward.\n",
        "        next_state,reward,done=road.step(action)\n",
        "        q_next_state=self.state_encode(next_state)\n",
        "\n",
        "        #SARSA - We follow the eps-policy for finding the Q-value of next state\n",
        "        next_action_set=self.road.get_possible_actions(next_state)\n",
        "        explore_p=random.random()\n",
        "        if explore_p<epsilon:\n",
        "          next_action=random.choice(next_action_set)\n",
        "        else:\n",
        "          next_action=next_action_set[np.argmax(self.q[q_next_state,next_action_set])]\n",
        "        #Greedy update \n",
        "        self.q[state,action]=self.q[state,action]+alpha*(reward+gamma*self.q[q_next_state,next_action]-self.q[state,action])\n",
        "    self.update_current_policy()\n",
        "\n",
        "    def erase_learning(self):\n",
        "      self.q=0.5\n",
        "      self.policy=0\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H8UGezhN5xA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "road=CliffRoad(5,8)\n",
        "agent=Agent(road)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1PGqZ-USop7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent.sarsa()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDY9LFnhSrut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "56974e1e-8b76-45a4-e2f2-900fe5171c2d"
      },
      "source": [
        "agent.policy"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 2, 2],\n",
              "       [1, 0, 0, 0, 1, 0, 1, 2],\n",
              "       [0, 0, 0, 1, 1, 3, 1, 2],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88dPl7-gN51P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent.q_learn()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IOR0Bh8N54Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "5b9ae6b4-0016-4e5f-c0a2-05bb4e601e30"
      },
      "source": [
        "agent.policy"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 2, 1, 2, 2, 2, 2],\n",
              "       [1, 3, 2, 1, 1, 1, 2, 2],\n",
              "       [1, 0, 2, 1, 1, 2, 1, 2],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 2],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQW8CSEZN57d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhAJ6tEpN5-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teBVPpmVs_KZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def state_encode(state,ncol):\n",
        "  encoded_state=state[0]*ncol+state[1]\n",
        "  if encoded_state<0:\n",
        "    return encoded_state%4\n",
        "  return encoded_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzElNyw5kbO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b06b3238-42c5-4e4d-88f8-ddf798ddc299"
      },
      "source": [
        "random.random()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39565831149966535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CpERjcghJAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Learning Parameters\n",
        "episodes=10\n",
        "alpha=.5\n",
        "gamma=.99\n",
        "epsilon=0.1\n",
        "\n",
        "\n",
        "\n",
        "road=CliffRoad(4,8)\n",
        "nrow=road.nrow\n",
        "ncol=road.ncol\n",
        "state_number=nrow*ncol\n",
        "action_number=4\n",
        "#initializing q-table\n",
        "q=np.full((state_number,action_number),0.5)\n",
        "exp_i=0\n",
        "for i in range(1000):\n",
        "  road.reset()\n",
        "  done=False\n",
        "  while not done:\n",
        "    state=state_encode(road.current_state,ncol)\n",
        "    action_set=road.get_possible_actions(road.current_state)\n",
        "    \n",
        "    explore_p=random.random()\n",
        "    if explore_p<epsilon:\n",
        "      action=random.choice(action_set)\n",
        "      # exp_i+=1\n",
        "      # print(\"Exploring:\",exp_i,road.current_state)\n",
        "\n",
        "    else:\n",
        "      action=action_set[np.argmax(q[state,action_set])]\n",
        "    next_state,reward,done=road.step(action)\n",
        "    q_next_state=state_encode(next_state,ncol)\n",
        "    next_action_set=road.get_possible_actions(next_state)\n",
        "    next_action=next_action_set[np.argmax(q[q_next_state,next_action_set])]\n",
        "\n",
        "    #update \n",
        "    q[state,action]=q[state,action]+alpha*(reward+gamma*q[q_next_state,next_action]-q[state,action])\n",
        "    # road.show_agent_position()\n",
        "    # print(road.current_state)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv9wGN7dA8Ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Learning Parameters\n",
        "episodes=10\n",
        "alpha=.5\n",
        "gamma=.99\n",
        "epsilon=0.1\n",
        "\n",
        "\n",
        "\n",
        "road=CliffRoad(4,8)\n",
        "nrow=road.nrow\n",
        "ncol=road.ncol\n",
        "state_number=nrow*ncol\n",
        "action_number=4\n",
        "#initializing q-table\n",
        "q=np.full((state_number,action_number),0.5)\n",
        "exp_i=0\n",
        "for i in range(1000):\n",
        "  road.reset()\n",
        "  done=False\n",
        "  while not done:\n",
        "    state=state_encode(road.current_state,ncol)\n",
        "    action_set=road.get_possible_actions(road.current_state)\n",
        "    \n",
        "    explore_p=random.random()\n",
        "    if explore_p<epsilon:\n",
        "      action=random.choice(action_set)\n",
        "      # exp_i+=1\n",
        "      # print(\"Exploring:\",exp_i,road.current_state)\n",
        "    else:\n",
        "      action=action_set[np.argmax(q[state,action_set])]\n",
        "\n",
        "    next_state,reward,done=road.step(action)\n",
        "    q_next_state=state_encode(next_state,ncol)\n",
        "    next_action_set=road.get_possible_actions(next_state)\n",
        "\n",
        "    explore_p=random.random()\n",
        "    if explore_p<epsilon:\n",
        "      next_action=random.choice(next_action_set)\n",
        "    else:\n",
        "      next_action=next_action_set[np.argmax(q[q_next_state,next_action_set])]\n",
        "\n",
        "    #update #sarsa\n",
        "\n",
        "    q[state,action]=q[state,action]+alpha*(reward+gamma*q[q_next_state,next_action]-q[state,action])\n",
        "    # road.show_agent_position()\n",
        "    # print(road.current_state)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smyRd4XB8bL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action_set=road.get_possible_actions(road.current_state)\n",
        "explore_p=.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KApDGpP88fqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action=action_set[np.argmax(q[state,action_set])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WBEy1vD9EpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da7e0e96-c4e9-48a4-b680-e381869f2246"
      },
      "source": [
        "next_action_set=road.get_possible_actions(next_state)\n",
        "next_action_set"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcXPe2ws9P4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "684478a3-e5dc-46eb-a429-dfceb31e17e4"
      },
      "source": [
        "next_action=next_action_set[np.argmax(q[28,next_action_set])]\n",
        "next_action"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-64Wewim90TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "next_state,reward,done=road.step(action)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-twebbL2-gyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGdh5Og69dPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee25e36a-0d84-4aa3-8510-83cb81083773"
      },
      "source": [
        "next_state"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy4gwkBwA4qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW37gvej8OCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action_set=road.get_possible_actions(road.current_state)\n",
        "\n",
        "explore_p=random.random()\n",
        "if explore_p<epsilon:\n",
        "  action=random.choice(action_set)\n",
        "  exp_i+=1\n",
        "  print(\"Exploring:\",exp_i,road.current_state)\n",
        "\n",
        "else:\n",
        "  action=action_set[np.argmax(q[state,action_set])]\n",
        "next_state,reward,done=road.step(action)\n",
        "q_next_state=state_encode(next_state,ncol)\n",
        "next_action_set=road.get_possible_actions(next_state)\n",
        "next_action=next_action_set[np.argmax(q[q_next_state,next_action_set])]\n",
        "\n",
        "#update \n",
        "q[state,action]=q[state,action]+alpha*(reward+gamma*q[q_next_state,next_action]-q[state,action])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZS38sXV1yWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "road.current_state=[2,4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mED_fZJA1je0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "178036e8-e7f0-4cc2-93a3-315ccd44a167"
      },
      "source": [
        "state_encode(road.current_state,8)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMJMB6watmQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a3d5d9c1-251b-4e69-fb1f-e38bb7963c25"
      },
      "source": [
        "road.reward_array"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  -1.,   -1.,   -1.,   -1.,   -1.,   -1.,   -1.,   -1.],\n",
              "       [  -1.,   -1.,   -1.,   -1.,   -1.,   -1.,   -1.,   -1.],\n",
              "       [  -1.,   -1.,   -1.,   -1.,   -1.,   -1.,   -1.,   -1.],\n",
              "       [  -1., -100., -100., -100., -100., -100., -100.,   -1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITEPp41vvf-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_policy(road,q):\n",
        "  nrow=road.nrow\n",
        "  ncol=road.ncol\n",
        "  policy_array=np.zeros_like(road.road)\n",
        "  for i in range(nrow):\n",
        "    for j in range(ncol):\n",
        "      state=[i,j]\n",
        "      action_set=road.get_possible_actions(state)\n",
        "      q_state=state_encode(state,ncol)\n",
        "      policy_array[i,j]=action_set[np.argmax(q[q_state,action_set])]\n",
        "  return policy_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlFh-yYzx23N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5e35c8be-8ad9-4812-c810-35b8eafeac88"
      },
      "source": [
        "get_policy(road,q)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 1, 1, 2, 2, 2, 2],\n",
              "       [1, 1, 1, 2, 1, 2, 1, 2],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 2],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UytGqg2MBXgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3ca9df59-fcab-42de-d9e0-89bfdb784d55"
      },
      "source": [
        "get_policy(road,q)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 2],\n",
              "       [0, 1, 1, 1, 0, 0, 1, 2],\n",
              "       [0, 0, 0, 0, 0, 3, 1, 2],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDxWmBVZiVv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action_set=road.get_possible_actions()\n",
        "action=action_set[np.argmax(q[state,action_set])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2AwYmqtvejs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiDWdLEtmATc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(q,road):\n",
        "  road.reset()\n",
        "  done=False\n",
        "  while not done:\n",
        "    state=state_encode(road.current_state,road.ncol)\n",
        "    action_set=road.get_possible_actions(road.current_state)\n",
        "    action=action_set[np.argmax(q[state,action_set])]\n",
        "    next_state,reward,done=road.step(action)\n",
        "    road.show_agent_position()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ch1x3bkmcQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "61a64c9d-62cd-4906-98d8-1653f70bb43f"
      },
      "source": [
        "infer(q,road)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1 1 1 1 1 1]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [8 0 0 0 0 0 0 0]\n",
            " [4 2 2 2 2 2 2 5]]\n",
            "[[1 1 1 1 1 1 1 1]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 8 0 0 0 0 0 0]\n",
            " [4 2 2 2 2 2 2 5]]\n",
            "[[1 1 1 1 1 1 1 1]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 8 0 0 0 0 0]\n",
            " [4 2 2 2 2 2 2 5]]\n",
            "[[1 1 1 1 1 1 1 1]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 8 0 0 0 0]\n",
            " [4 2 2 2 2 2 2 5]]\n",
            "[[1 1 1 1 1 1 1 1]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 8 0 0 0]\n",
            " [4 2 2 2 2 2 2 5]]\n",
            "[[1 1 1 1 1 1 1 1]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [4 2 2 2 8 2 2 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U5AFWI5Ra-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_episode():\n",
        "  episodes=10\n",
        "  alpha=.5\n",
        "  gamma=.99\n",
        "\n",
        "  road=CliffRoad(4,8)\n",
        "  nrow=road.nrow\n",
        "  ncol=road.ncol\n",
        "  state_number=nrow*ncol\n",
        "  action_number=4\n",
        "  done=False\n",
        "\n",
        "  #initializing q-table\n",
        "  q=np.full((state_number,action_number),0.5)\n",
        "  while not done:\n",
        "    state=state_encode(road.current_state,road.ncol)\n",
        "    action_set=road.get_possible_actions()\n",
        "    print(road.current_state)\n",
        "    print(action_set)\n",
        "    action=action_set[np.argmax(q[state,action_set])]\n",
        "    next_state,reward,done=road.step(action)\n",
        "    q_next_state=state_encode(next_state,ncol)\n",
        "    #update \n",
        "    q[state,action]=q[state,action]+alpha*(reward+gamma*q[q_next_state,action]-q[state,action])\n",
        "    road.show_agent_position()\n",
        "  print(q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcIRunGeiftU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9sT5dYAifxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}